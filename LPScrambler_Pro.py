import os
import random
import string
import json
import uuid
import shutil
import re
from bs4 import BeautifulSoup

class LPScramblerPro:
    def __init__(self, template_path, output_dir="dist_lp"):
        self.template_path = template_path
        self.output_dir = output_dir
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨ï¼Œæ¯æ¬¡è¿è¡Œæ¸…ç©ºæ—§ç›®å½•ï¼Œç¡®ä¿ä¸ç•™æ—§æŒ‡çº¹ [cite: 1]
        if os.path.exists(self.output_dir):
            shutil.rmtree(self.output_dir) 
        os.makedirs(self.output_dir, exist_ok=True)
        self.map = {}

    def _rand_str(self, length=8):
        """ç”Ÿæˆéšæœºå°å†™å­—æ¯å­—ç¬¦ä¸²ç”¨äºæ··æ·†ç±»åå’ŒID [cite: 2]"""
        return ''.join(random.choices(string.ascii_lowercase, k=length))

    def _xor_cipher(self, text):
        """æ ¸å¿ƒå¤šæ€åŠ å¯†é€»è¾‘ï¼šé‡‡ç”¨éšæœºå¯†é’¥è¿›è¡Œå¼‚æˆ–è¿ç®— [cite: 2]"""
        key = random.randint(10, 250)
        encoded = [ord(c) ^ key for c in text]
        return encoded, key

    def _auto_copy_assets(self, soup):
        """
        è‡ªåŠ¨åŒ–èµ„æºä¿®å¤é€»è¾‘ï¼š
        æ‰«æ HTML æ¨¡æ¿ä¸­å¼•ç”¨çš„æ‰€æœ‰æœ¬åœ°å›¾ç‰‡/èµ„æºï¼Œå¹¶è‡ªåŠ¨æ‹·è´åˆ°è¾“å‡ºç›®å½• [cite: 3]ã€‚
        """
        asset_tags = {'img': 'src', 'link': 'href', 'script': 'src'}
        for tag_name, attr in asset_tags.items():
            for element in soup.find_all(tag_name):
                src = element.get(attr)
                if src and not src.startswith(('http', '//', 'data:')):
                    # ä»…å¤„ç†æœ¬åœ°è·¯å¾„ [cite: 4]
                    src_path = os.path.join(os.path.dirname(self.template_path) if os.path.dirname(self.template_path) else ".", src)
                    if os.path.exists(src_path):
                        dest_path = os.path.join(self.output_dir, src)
                        os.makedirs(os.path.dirname(dest_path), exist_ok=True) # [cite: 5]
                        shutil.copy(src_path, dest_path)
                        print(f"ğŸ“¦ å·²è‡ªåŠ¨è¿ç§»èµ„æº: {src}")

    def scramble(self):
        self.map = {} # ç¡®ä¿å•æ¬¡è¿è¡ŒæŒ‡çº¹å”¯ä¸€ [cite: 6]
        
        if not os.path.exists(self.template_path):
            print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ¨¡æ¿æ–‡ä»¶ {self.template_path}") # [cite: 6]
            return

        with open(self.template_path, 'r', encoding='utf-8') as f: # [cite: 6]
            soup = BeautifulSoup(f.read(), 'html.parser')

        # 1. ç»“æ„æŒ‡çº¹éšæœºåŒ– [cite: 6]
        for tag in soup.find_all(True):
            if tag.has_attr('class'): # [cite: 6]
                tag['class'] = [self.map.setdefault(c, self._rand_str()) for c in tag['class']] # [cite: 7]
            if tag.has_attr('id'): # [cite: 7]
                tag['id'] = self.map.setdefault(tag['id'], self._rand_str())
            
            # æ³¨å…¥æ··æ·†å±æ€§ [cite: 7, 8]
            tag[f"data-v-{self._rand_str(5)}"] = ""
            tag[f"data-x-{self._rand_str(4)}"] = self._rand_str(6)

        # 2. å†…å®¹å±‚å¤šæ€åŠ å¯† [cite: 8]
        target_id = self.map.get('main-content')
        if target_id:
            target_node = soup.find(id=target_id) # [cite: 8]
            if target_node:
                raw_content = "".join([str(x) for x in target_node.contents]) # [cite: 8]
                encoded_data, key = self._xor_cipher(raw_content) # [cite: 9]
                target_node.clear() # [cite: 9]

                # éšæœºåŒ– JS å˜é‡åä»¥æ¶ˆé™¤è§£å¯†æŒ‡çº¹ [cite: 9]
                v_data, v_key, v_res = self._rand_str(4), self._rand_str(4), self._rand_str(4)
                
                js_logic = f"""
                (function(){{
                    var {v_data} = {json.dumps(encoded_data)}, {v_key} = {key};
                    if(navigator.webdriver) return; // 
                    setTimeout(function(){{
                        var {v_res} = {v_data}.map(function(c){{ return String.fromCharCode(c ^ {v_key}); }}).join(''); // [cite: 12]
                        document.getElementById('{target_id}').innerHTML = {v_res}; // [cite: 12]
                    }}, {random.randint(200, 500)}); // [cite: 12]
                }})();
                """
                script_tag = soup.new_tag("script")
                script_tag.string = js_logic
                soup.body.append(script_tag)

        # 3. æ ·å¼ç‰¹å¾æ±¡æŸ“ [cite: 13, 14]
        style_tag = soup.new_tag("style")
        style_tag.string = f":root {{ --{self._rand_str()}: {random.randint(1,100)}; }}" 
        soup.head.append(style_tag)

        # 4. è‡ªåŠ¨åŒ–èµ„æºæ‹·è´ [cite: 14]
        self._auto_copy_assets(soup)

        # 5. æ–‡ä»¶ä¿å­˜
        save_path = os.path.join(self.output_dir, "index.html")
        with open(save_path, 'w', encoding='utf-8') as f:
            f.write(soup.prettify())
        
        print(f"\nâœ¨ æ··æ·†ä»»åŠ¡åœ†æ»¡å®Œæˆï¼")
        print(f"ğŸ“‚ è¯·ç›´æ¥ä½¿ç”¨ç›®å½•: {os.path.abspath(self.output_dir)}")

if __name__ == "__main__":
    try:
        # [cite: 15]
        target_file = "index.html" 
        scrambler = LPScramblerPro(target_file)
        scrambler.scramble()
    except Exception as e:
        print(f"\nâŒ è¿è¡Œå‘ç”Ÿè‡´å‘½é”™è¯¯: {e}")
    
    # æ ¸å¿ƒé˜²é—ªé€€é€»è¾‘ï¼šç­‰å¾…ç”¨æˆ·è¾“å…¥
    print("\n" + "="*30)
    input("ç¨‹åºæ‰§è¡Œå®Œæ¯•ï¼ŒæŒ‰å›è½¦é”®(Enter)é€€å‡º...")
