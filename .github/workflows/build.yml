import os
import random
import string
import json
import uuid
import shutil
import re
from bs4 import BeautifulSoup

class LPScramblerPro:
    def __init__(self, template_path, output_dir="dist_lp"):
        self.template_path = template_path
        self.output_dir = output_dir
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        if os.path.exists(self.output_dir):
            shutil.rmtree(self.output_dir) # æ¯æ¬¡è¿è¡Œæ¸…ç©ºæ—§ç›®å½•ï¼Œç¡®ä¿ä¸ç•™æ—§æŒ‡çº¹
        os.makedirs(self.output_dir, exist_ok=True)
        self.map = {}

    def _rand_str(self, length=8):
        """ç”Ÿæˆéšæœºå°å†™å­—æ¯å­—ç¬¦ä¸²ç”¨äºæ··æ·†ç±»åå’ŒID"""
        return ''.join(random.choices(string.ascii_lowercase, k=length))

    def _xor_cipher(self, text):
        """æ ¸å¿ƒå¤šæ€åŠ å¯†é€»è¾‘ï¼šé‡‡ç”¨éšæœºå¯†é’¥è¿›è¡Œå¼‚æˆ–è¿ç®—"""
        key = random.randint(10, 250)
        encoded = [ord(c) ^ key for c in text]
        return encoded, key

    def _auto_copy_assets(self, soup):
        """
        è‡ªåŠ¨åŒ–èµ„æºä¿®å¤é€»è¾‘ï¼š
        æ‰«æ HTML æ¨¡æ¿ä¸­å¼•ç”¨çš„æ‰€æœ‰æœ¬åœ°å›¾ç‰‡/èµ„æºï¼Œå¹¶è‡ªåŠ¨æ‹·è´åˆ°è¾“å‡ºç›®å½•ã€‚
        """
        asset_tags = {'img': 'src', 'link': 'href', 'script': 'src'}
        for tag_name, attr in asset_tags.items():
            for element in soup.find_all(tag_name):
                src = element.get(attr)
                if src and not src.startswith(('http', '//', 'data:')):
                    # ä»…å¤„ç†æœ¬åœ°è·¯å¾„
                    src_path = os.path.join(os.path.dirname(self.template_path) if os.path.dirname(self.template_path) else ".", src)
                    if os.path.exists(src_path):
                        dest_path = os.path.join(self.output_dir, src)
                        os.makedirs(os.path.dirname(dest_path), exist_ok=True)
                        shutil.copy(src_path, dest_path)
                        print(f"ğŸ“¦ å·²è‡ªåŠ¨è¿ç§»èµ„æº: {src}")

    def scramble(self):
        self.map = {} # ç¡®ä¿å•æ¬¡è¿è¡ŒæŒ‡çº¹å”¯ä¸€
        
        if not os.path.exists(self.template_path):
            print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ¨¡æ¿æ–‡ä»¶ {self.template_path}")
            return

        with open(self.template_path, 'r', encoding='utf-8') as f:
            soup = BeautifulSoup(f.read(), 'html.parser')

        # 1. ç»“æ„æŒ‡çº¹éšæœºåŒ–
        for tag in soup.find_all(True):
            if tag.has_attr('class'):
                tag['class'] = [self.map.setdefault(c, self._rand_str()) for c in tag['class']]
            if tag.has_attr('id'):
                tag['id'] = self.map.setdefault(tag['id'], self._rand_str())
            
            # æ³¨å…¥æ··æ·†å±æ€§
            tag[f"data-v-{self._rand_str(5)}"] = ""
            tag[f"data-x-{self._rand_str(4)}"] = self._rand_str(6)

        # 2. å†…å®¹å±‚å¤šæ€åŠ å¯†
        target_id = self.map.get('main-content')
        if target_id:
            target_node = soup.find(id=target_id)
            if target_node:
                raw_content = "".join([str(x) for x in target_node.contents])
                encoded_data, key = self._xor_cipher(raw_content)
                target_node.clear()

                # éšæœºåŒ– JS å˜é‡åä»¥æ¶ˆé™¤è§£å¯†æŒ‡çº¹
                v_data, v_key, v_res = self._rand_str(4), self._rand_str(4), self._rand_str(4)
                
                js_logic = f"""
                (function(){{
                    var {v_data} = {json.dumps(encoded_data)}, {v_key} = {key};
                    if(navigator.webdriver) return;
                    setTimeout(function(){{
                        var {v_res} = {v_data}.map(function(c){{ return String.fromCharCode(c ^ {v_key}); }}).join('');
                        document.getElementById('{target_id}').innerHTML = {v_res};
                    }}, {random.randint(200, 500)});
                }})();
                """
                script_tag = soup.new_tag("script")
                script_tag.string = js_logic
                soup.body.append(script_tag)

        # 3. æ ·å¼ç‰¹å¾æ±¡æŸ“
        style_tag = soup.new_tag("style")
        style_tag.string = f":root {{ --{self._rand_str()}: {random.randint(1,100)}; }}"
        soup.head.append(style_tag)

        # 4. è‡ªåŠ¨åŒ–èµ„æºæ‹·è´
        self._auto_copy_assets(soup)

        # 5. æ–‡ä»¶ä¿å­˜
        save_path = os.path.join(self.output_dir, "index.html")
        with open(save_path, 'w', encoding='utf-8') as f:
            f.write(soup.prettify())
        
        print(f"\nâœ¨ æ··æ·†ä»»åŠ¡åœ†æ»¡å®Œæˆï¼")
        print(f"ğŸ“‚ è¯·ç›´æ¥ä½¿ç”¨ç›®å½•: {os.path.abspath(self.output_dir)}")

if __name__ == "__main__":
    target_file = "index.html" 
    scrambler = LPScramblerPro(target_file)
    scrambler.scramble()
